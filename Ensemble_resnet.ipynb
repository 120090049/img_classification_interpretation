{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":19.351342,"end_time":"2022-02-23T10:03:06.247288","exception":false,"start_time":"2022-02-23T10:02:46.895946","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["import numpy as np \n","import pandas as pd \n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        pass"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":0.0189,"end_time":"2022-02-23T10:03:06.279758","exception":false,"start_time":"2022-02-23T10:03:06.260858","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["_exp_name = \"sample\""]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":1.654263,"end_time":"2022-02-23T10:03:07.947242","exception":false,"start_time":"2022-02-23T10:03:06.292979","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Import necessary packages.\n","import numpy as np\n","import torch\n","import os\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","from PIL import Image\n","# \"ConcatDataset\" and \"Subset\" are possibly useful when doing semi-supervised learning.\n","from torch.utils.data import ConcatDataset, DataLoader, Subset, Dataset\n","from torchvision.datasets import DatasetFolder, VisionDataset\n","\n","# This is for the progress bar.\n","from tqdm.auto import tqdm\n","import random"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":0.078771,"end_time":"2022-02-23T10:03:08.039428","exception":false,"start_time":"2022-02-23T10:03:07.960657","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["myseed = 6666  # set a random seed for reproducibility\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","np.random.seed(myseed)\n","torch.manual_seed(myseed)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(myseed)\n","    \n","input_size = 224"]},{"attachments":{},"cell_type":"markdown","metadata":{"papermill":{"duration":0.01289,"end_time":"2022-02-23T10:03:08.065357","exception":false,"start_time":"2022-02-23T10:03:08.052467","status":"completed"},"tags":[]},"source":["## **Transforms**"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":0.021406,"end_time":"2022-02-23T10:03:08.099437","exception":false,"start_time":"2022-02-23T10:03:08.078031","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["\n","test_tfm = transforms.Compose([\n","    transforms.Resize((input_size, input_size)),\n","    transforms.ToTensor(),\n","])\n","\n","\n","train_tfm = transforms.Compose([\n","    # Resize the image into a fixed shape (height = width = 128)\n","    transforms.RandomResizedCrop((input_size, input_size), scale=(0.7, 1.0)),\n","    #transforms.AutoAugment(transforms.AutoAugmentPolicy.IMAGENET),\n","    #transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n","    transforms.RandomHorizontalFlip(0.5),\n","    transforms.RandomVerticalFlip(0.5),\n","    transforms.RandomRotation(30),\n","    transforms.RandomAffine(30),\n","\n","    transforms.RandomPerspective(distortion_scale=0.2, p=0.5),\n","\n","    transforms.ToTensor(),\n","])\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"papermill":{"duration":0.012739,"end_time":"2022-02-23T10:03:08.125181","exception":false,"start_time":"2022-02-23T10:03:08.112442","status":"completed"},"tags":[]},"source":["## **Datasets**"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":0.023022,"end_time":"2022-02-23T10:03:08.160912","exception":false,"start_time":"2022-02-23T10:03:08.13789","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# class FoodDataset(Dataset):\n","\n","class FoodDataset(Dataset):\n","\n","    def __init__(self,path,tfm=test_tfm,files = None):\n","        super(FoodDataset).__init__()\n","        self.path = path\n","        self.files = sorted([os.path.join(path,x) for x in os.listdir(path) if x.endswith(\".jpg\")])\n","        if files != None:\n","            self.files = files\n","        print(f\"One {path} sample\",self.files[0])\n","        self.transform = tfm\n","  \n","    def __len__(self):\n","        return len(self.files)\n","  \n","    def __getitem__(self,idx):\n","        fname = self.files[idx]\n","        im = Image.open(fname)\n","        im = self.transform(im)\n","        #im = self.data[idx]\n","        try:\n","            label = int(fname.split(\"/\")[-1].split(\"_\")[0])\n","        except:\n","            label = -1 # test has no label\n","        return im,label\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"papermill":{"duration":0.0258,"end_time":"2022-02-23T10:03:08.199437","exception":false,"start_time":"2022-02-23T10:03:08.173637","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["import torchvision.models as models\n","\n","class Classifier(nn.Module):\n","    def __init__(self):\n","        super(Classifier, self).__init__()\n","        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n","        # torch.nn.MaxPool2d(kernel_size, stride, padding)\n","        # input 維度 [3, 224, 224]\n","        vgg16 = models.vgg16(pretrained=True)\n","        cnn = vgg16.features\n","        for param in cnn.parameters():\n","            param.requires_grad = False\n","        self.cnn = cnn\n","        \n","        self.connect = nn.Sequential(\n","            nn.Conv2d(512, 64, kernel_size=3, stride=1, padding=0),\n","#             nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=0)\n","        )\n","        \n","        self.fc = nn.Sequential(\n","            nn.Dropout(0.4),\n","            nn.Linear(64*5*5, 1024),\n","            nn.ReLU(),\n","            nn.Linear(1024, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 11)\n","        )\n","        state_dict = vgg16.state_dict()\n","        self_state_dict = self.state_dict()\n","\n","        # 只复制相同层的参数\n","        for name, param in state_dict.items():\n","            if name in self_state_dict:\n","                self_state_dict[name].copy_(param)\n","\n","    def forward(self, x):\n","        out = self.cnn(x.float())\n","        out = self.connect(out)\n","        out = out.view(out.size()[0], -1)\n","        return self.fc(out)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["import torch.nn.functional as F\n","from torch.autograd import Variable\n","\n","class FocalLoss(nn.Module):\n","    def __init__(self, class_num, alpha=None, gamma=2, size_average=True):\n","        super().__init__()\n","        if alpha is None:\n","            self.alpha = Variable(torch.ones(class_num, 1))\n","        else:\n","            if isinstance(alpha, Variable):\n","                self.alpha = alpha\n","            else:\n","                self.alpha = Variable(alpha)\n","        self.gamma = gamma\n","        self.class_num = class_num\n","        self.size_average = size_average\n","        \n","    def forward(self, inputs, targets):\n","        N = inputs.size(0)\n","        C = inputs.size(1)\n","        P = F.softmax(inputs, dim=1)\n","        \n","        class_mask = inputs.data.new(N, C).fill_(0)\n","        class_mask = Variable(class_mask)\n","        ids = targets.view(-1, 1)\n","        class_mask.scatter_(1, ids.data, 1.)\n","        \n","        if inputs.is_cuda and not self.alpha.is_cuda:\n","            self.alpha = self.alpha.cuda()\n","        alpha = self.alpha[ids.data.view(-1)]\n","        probs = (P*class_mask).sum(1).view(-1, 1)\n","        \n","        log_p = probs.log()\n","        \n","        batch_loss = -alpha*(torch.pow((1-probs), self.gamma))*log_p\n","        \n","        if self.size_average:\n","            loss = batch_loss.mean()\n","        else:\n","            loss = batch_loss.sum()\n","            \n","        return loss\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install torchsummary\n","from torchsummary import summary\n","\n","model_show = Classifier().to('cuda')\n","summary(model_show, input_size=(3, input_size, input_size))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":0.054295,"end_time":"2022-02-23T10:03:08.266338","exception":false,"start_time":"2022-02-23T10:03:08.212043","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["batch_size = 64\n","_dataset_dir = \".\\\\food11\"\n","\n","# The number of training epochs and patience.\n","n_epochs = 20\n","patience = 6 # If no improvement in 'patience' epochs, early stop\n","k_fold = 4\n","\n","\n","# Dataset\n","train_dir = \".\\\\food11\\\\training\"\n","val_dir = \".\\\\food11\\\\validation\"\n","\n","train_files = [os.path.join(train_dir, x) for x in os.listdir(train_dir) if x.endswith('.jpg')]\n","val_files = [os.path.join(val_dir, x) for x in os.listdir(val_dir) if x.endswith('.jpg')]\n","total_files = train_files + val_files\n","random.shuffle(total_files)\n","\n","num = len(total_files) // k_fold\n"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":32830.720158,"end_time":"2022-02-23T19:10:19.001001","exception":false,"start_time":"2022-02-23T10:03:08.280843","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["from torch.utils.tensorboard import SummaryWriter\n","writer = SummaryWriter()\n","\n","\n","\n","# \"cuda\" only when GPUs are available.\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(device)\n","\n","# The number of training epochs and patience.\n","\n","\n","# Initialize a model, and put it on the device specified.\n","\n","#from torchsummary import summary\n","#summary(model, (3, 128, 128))\n","# For the classification task, we use cross-entropy as the measurement of performance.\n","#criterion = nn.CrossEntropyLoss()\n","\n","# Initialize optimizer, you may fine-tune some hyperparameters such as learning rate on your own.\n","\n","# Initialize trackers, these are not parameters and should not be changed\n","\n","test_fold = k_fold\n","\n","for i in range(test_fold):\n","    fold = i+1\n","    print(f'\\n\\nStarting Fold: {fold} ********************************************')\n","\n","    model = Classifier().to(device)\n","#     model = Classifier(Residual_Block, num_layers).to(device)\n","\n","#     criterion = nn.CrossEntropyLoss()\n","    criterion = FocalLoss(11, alpha=None)\n","\n","    # Initialize optimizer, you may fine-tune some hyperparameters such as learning rate on your own.\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.0003, weight_decay=1e-5) \n","    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=16, T_mult=1)\n","\n","    stale = 0\n","    best_acc = 0\n","    \n","    val_data = total_files[i*num: (i+1)*num]\n","    train_data = total_files[:i*num] + total_files[(i+1)*num:]\n","    \n","    train_set = FoodDataset(os.path.join(_dataset_dir,\"training\"), tfm=train_tfm, files=train_data)\n","    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n","    \n","    valid_set = FoodDataset(os.path.join(_dataset_dir,\"validation\"), tfm=test_tfm, files=val_data)\n","    valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n","    \n","    for epoch in range(n_epochs):\n","    \n","        # ---------- Training ----------\n","        # Make sure the model is in train mode before training.\n","        model.train()\n","    \n","        # These are used to record information in training.\n","        train_loss = []\n","        train_accs = []\n","        lr = optimizer.param_groups[0][\"lr\"]\n","        \n","        pbar = tqdm(train_loader)\n","        pbar.set_description(f'T: {epoch+1:03d}/{n_epochs:03d}')\n","        for batch in pbar:\n","    \n","            # A batch consists of image data and corresponding labels.\n","            imgs, labels = batch\n","            #imgs = imgs.half()\n","            #print(imgs.shape,labels.shape)\n","    \n","            logits = model(imgs.to(device))\n","  \n","            loss = criterion(logits, labels.to(device))\n","    \n","            optimizer.zero_grad()\n","    \n","            loss.backward()\n","    \n","            # Clip the gradient norms for stable training.\n","            grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n","    \n","            optimizer.step()\n","    \n","            # Compute the accuracy for current batch.\n","            acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n","    \n","            train_loss.append(loss.item())\n","            train_accs.append(acc)\n","            pbar.set_postfix({'lr':lr, 'b_loss':loss.item(), 'b_acc':acc.item(),\n","                    'loss':sum(train_loss)/len(train_loss), 'acc': sum(train_accs).item()/len(train_accs)})\n","        \n","        scheduler.step()\n","        \n","        \n","        model.eval()\n","    \n","        valid_loss = []\n","        valid_accs = []\n","    \n","        pbar = tqdm(valid_loader)\n","        pbar.set_description(f'V: {epoch+1:03d}/{n_epochs:03d}')\n","        for batch in pbar:\n","\n","            imgs, labels = batch\n","    \n","            with torch.no_grad():\n","                logits = model(imgs.to(device))\n","    \n","            loss = criterion(logits, labels.to(device))\n","    \n","            # Compute the accuracy for current batch.\n","            acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n","    \n","            valid_loss.append(loss.item())\n","            valid_accs.append(acc)\n","            pbar.set_postfix({'v_loss':sum(valid_loss)/len(valid_loss), \n","                              'v_acc': sum(valid_accs).item()/len(valid_accs)})\n","        \n","    \n","        # The average loss and accuracy for entire validation set is the average of the recorded values.\n","        valid_loss = sum(valid_loss) / len(valid_loss)\n","        valid_acc = sum(valid_accs) / len(valid_accs)\n","    \n","    \n","        if valid_acc > best_acc:\n","            print(f\"Best model found at fold {fold} epoch {epoch+1}, acc={valid_acc:.5f}, saving model\")\n","            torch.save(model.state_dict(), f\"Fold_{fold}_best.ckpt\")\n","            # only save best to prevent output memory exceed error\n","            best_acc = valid_acc\n","            stale = 0\n","        else:\n","            stale += 1\n","            if stale > patience:\n","                print(f\"No improvment {patience} consecutive epochs, early stopping\")\n","                break"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# %reload_ext tensorboard\n","# %tensorboard --logdir=./runs/"]},{"attachments":{},"cell_type":"markdown","metadata":{"papermill":{"duration":0.498773,"end_time":"2022-02-23T19:10:20.961802","exception":false,"start_time":"2022-02-23T19:10:20.463029","status":"completed"},"tags":[]},"source":["## Testing and generate prediction CSV"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":0.493644,"end_time":"2022-02-23T19:10:19.985992","exception":false,"start_time":"2022-02-23T19:10:19.492348","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["test_set = FoodDataset(os.path.join(_dataset_dir,\"test\"), tfm=test_tfm)\n","test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)"]},{"cell_type":"code","execution_count":32,"metadata":{"papermill":{"duration":49.157727,"end_time":"2022-02-23T19:11:10.61523","exception":false,"start_time":"2022-02-23T19:10:21.457503","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["from scipy.stats import norm\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","my_models = []\n","test_fold = 4\n","for i in range(test_fold):\n","    fold = i + 1\n","    model_best = Classifier().to(device)\n","    model_best.load_state_dict(torch.load(f\"Fold_{fold}_best.ckpt\"))\n","    model_best.eval()\n","    my_models.append(model_best)\n","\n","prediction = []            \n","with torch.no_grad():\n","    for data,_ in test_loader:\n","        test_preds = [] \n","        for model_best in my_models:\n","            x = model_best(data.to(device)).cpu().data.numpy()\n","            x_norm = (x - x.mean()) / x.std()\n","            test_preds.append(x_norm)\n","        test_preds = sum(test_preds)\n","        test_label = np.argmax(test_preds, axis=1)\n","        prediction += test_label.squeeze().tolist()\n"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["-0.5943599036363637 3.9709771358870882\n"]}],"source":["x = [-2.3858778,   2.7100792,   6.421224,   -2.6665208,   0.42138156, -5.097257, -3.9062247,  -4.0514126,  -1.2747383,   6.699804,   -3.4084165 ]\n","x = np.array(x)\n","print(x.mean(), x.std())\n"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"ename":"AttributeError","evalue":"'list' object has no attribute 'numpy'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test_preds \u001b[39m=\u001b[39m [[\u001b[39m1\u001b[39;49m,\u001b[39m2\u001b[39;49m,\u001b[39m3\u001b[39;49m]\u001b[39m.\u001b[39;49mnumpy(),[\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m]\u001b[39m.\u001b[39mnumpy(),[\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m]\u001b[39m.\u001b[39mnumpy()]\n\u001b[0;32m      2\u001b[0m test_preds \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(test_preds)\n\u001b[0;32m      3\u001b[0m prediction(test_preds)\n","\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'numpy'"]}],"source":["test_preds = [[1,2,3].numpy(),[1,2,3].numpy(),[1,2,3].numpy()]\n","test_preds = sum(test_preds)\n","prediction(test_preds)\n","test_label = np.argmax(test_preds, axis=1)\n","print(test_label)"]},{"cell_type":"code","execution_count":34,"metadata":{"papermill":{"duration":0.554276,"end_time":"2022-02-23T19:11:11.870035","exception":false,"start_time":"2022-02-23T19:11:11.315759","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["#create test csv\n","import pandas as pd\n","def pad4(i):\n","    return \"0\"*(4-len(str(i)))+str(i)\n","df = pd.DataFrame()\n","df[\"Id\"] = [pad4(i) for i in range(1,len(test_set)+1)]\n","df[\"Category\"] = prediction\n","df.to_csv(\"submission.csv\",index = False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"pytorch39","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":4}
