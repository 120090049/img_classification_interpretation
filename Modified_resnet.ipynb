{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-05-06T13:21:33.811988Z","iopub.status.busy":"2023-05-06T13:21:33.811479Z","iopub.status.idle":"2023-05-06T13:21:47.699990Z","shell.execute_reply":"2023-05-06T13:21:47.699153Z","shell.execute_reply.started":"2023-05-06T13:21:33.811943Z"},"papermill":{"duration":19.351342,"end_time":"2022-02-23T10:03:06.247288","exception":false,"start_time":"2022-02-23T10:02:46.895946","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        pass\n","        #print(os.path.join(dirname, filename))\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-05-06T13:21:47.702326Z","iopub.status.busy":"2023-05-06T13:21:47.701578Z","iopub.status.idle":"2023-05-06T13:21:47.707156Z","shell.execute_reply":"2023-05-06T13:21:47.705601Z","shell.execute_reply.started":"2023-05-06T13:21:47.702295Z"},"papermill":{"duration":0.0189,"end_time":"2022-02-23T10:03:06.279758","exception":false,"start_time":"2022-02-23T10:03:06.260858","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["_exp_name = \"sample\""]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-05-06T13:21:47.708759Z","iopub.status.busy":"2023-05-06T13:21:47.708456Z","iopub.status.idle":"2023-05-06T13:21:51.824999Z","shell.execute_reply":"2023-05-06T13:21:51.824019Z","shell.execute_reply.started":"2023-05-06T13:21:47.708731Z"},"papermill":{"duration":1.654263,"end_time":"2022-02-23T10:03:07.947242","exception":false,"start_time":"2022-02-23T10:03:06.292979","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["d:\\ProgrammingSoftwares\\Anaconda3\\envs\\pytorch39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["# Import necessary packages.\n","import numpy as np\n","import torch\n","import os\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","from PIL import Image\n","# \"ConcatDataset\" and \"Subset\" are possibly useful when doing semi-supervised learning.\n","from torch.utils.data import ConcatDataset, DataLoader, Subset, Dataset\n","from torchvision.datasets import DatasetFolder, VisionDataset\n","\n","# This is for the progress bar.\n","from tqdm.auto import tqdm\n","import random"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-05-06T13:21:51.827516Z","iopub.status.busy":"2023-05-06T13:21:51.827033Z","iopub.status.idle":"2023-05-06T13:21:51.837203Z","shell.execute_reply":"2023-05-06T13:21:51.836286Z","shell.execute_reply.started":"2023-05-06T13:21:51.827487Z"},"papermill":{"duration":0.078771,"end_time":"2022-02-23T10:03:08.039428","exception":false,"start_time":"2022-02-23T10:03:07.960657","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["myseed = 6666  # set a random seed for reproducibility\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","np.random.seed(myseed)\n","torch.manual_seed(myseed)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(myseed)"]},{"attachments":{},"cell_type":"markdown","metadata":{"papermill":{"duration":0.01289,"end_time":"2022-02-23T10:03:08.065357","exception":false,"start_time":"2022-02-23T10:03:08.052467","status":"completed"},"tags":[]},"source":["## **Transforms**"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-05-06T13:21:51.838913Z","iopub.status.busy":"2023-05-06T13:21:51.838537Z","iopub.status.idle":"2023-05-06T13:21:51.848534Z","shell.execute_reply":"2023-05-06T13:21:51.847638Z","shell.execute_reply.started":"2023-05-06T13:21:51.838847Z"},"papermill":{"duration":0.021406,"end_time":"2022-02-23T10:03:08.099437","exception":false,"start_time":"2022-02-23T10:03:08.078031","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Normally, We don't need augmentations in testing and validation.\n","# All we need here is to resize the PIL image and transform it into Tensor.\n","test_tfm = transforms.Compose([\n","    transforms.Resize((128, 128)),\n","    transforms.ToTensor(),\n","])\n","\n","# However, it is also possible to use augmentation in the testing phase.\n","# You may use train_tfm to produce a variety of images and then test using ensemble methods\n","train_tfm = transforms.Compose([\n","    # Resize the image into a fixed shape (height = width = 128)\n","    transforms.RandomResizedCrop((128, 128), scale=(0.7, 1.0)),\n","    #transforms.AutoAugment(transforms.AutoAugmentPolicy.IMAGENET),\n","    #transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n","    transforms.RandomHorizontalFlip(0.5),\n","    transforms.RandomVerticalFlip(0.5),\n","    transforms.RandomRotation(30),\n","    transforms.RandomAffine(30),\n","\n","    transforms.RandomPerspective(distortion_scale=0.2, p=0.5),\n","\n","    transforms.ToTensor(),\n","])\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"papermill":{"duration":0.012739,"end_time":"2022-02-23T10:03:08.125181","exception":false,"start_time":"2022-02-23T10:03:08.112442","status":"completed"},"tags":[]},"source":["## **Datasets**"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-05-06T13:21:51.850683Z","iopub.status.busy":"2023-05-06T13:21:51.849966Z","iopub.status.idle":"2023-05-06T13:21:51.867658Z","shell.execute_reply":"2023-05-06T13:21:51.866468Z","shell.execute_reply.started":"2023-05-06T13:21:51.850650Z"},"papermill":{"duration":0.023022,"end_time":"2022-02-23T10:03:08.160912","exception":false,"start_time":"2022-02-23T10:03:08.13789","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["class FoodDataset(Dataset):\n","\n","    def __init__(self,path,tfm=test_tfm,files = None):\n","        super(FoodDataset).__init__()\n","        self.path = path\n","        self.files = sorted([os.path.join(path,x) for x in os.listdir(path) if x.endswith(\".jpg\")])\n","        if files != None:\n","            self.files = files\n","        print(f\"One {path} sample\",self.files[0])\n","        self.transform = tfm\n","  \n","    def __len__(self):\n","        return len(self.files)\n","  \n","    def __getitem__(self,idx):\n","        fname = self.files[idx]\n","        im = Image.open(fname)\n","        im = self.transform(im)\n","        #im = self.data[idx]\n","        try:\n","            label = int(fname.split(\"/\")[-1].split(\"_\")[0])\n","        except:\n","            label = -1 # test has no label\n","        return im,label\n","\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-05-06T13:22:16.390906Z","iopub.status.busy":"2023-05-06T13:22:16.390491Z","iopub.status.idle":"2023-05-06T13:22:16.401300Z","shell.execute_reply":"2023-05-06T13:22:16.400285Z","shell.execute_reply.started":"2023-05-06T13:22:16.390874Z"},"papermill":{"duration":0.0258,"end_time":"2022-02-23T10:03:08.199437","exception":false,"start_time":"2022-02-23T10:03:08.173637","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["class Classifier(nn.Module):\n","    def __init__(self):\n","        super(Classifier, self).__init__()\n","        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n","        # torch.nn.MaxPool2d(kernel_size, stride, padding)\n","        # input 維度 [3, 128, 128]\n","        self.cnn = nn.Sequential(\n","            nn.Conv2d(3, 64, 3, 1, 1),  # [64, 128, 128]\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),      # [64, 64, 64]\n","\n","            nn.Conv2d(64, 128, 3, 1, 1), # [128, 64, 64]\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),      # [128, 32, 32]\n","\n","            nn.Conv2d(128, 256, 3, 1, 1), # [256, 32, 32]\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),      # [256, 16, 16]\n","\n","            nn.Conv2d(256, 512, 3, 1, 1), # [512, 16, 16]\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),       # [512, 8, 8]\n","            \n","            nn.Conv2d(512, 512, 3, 1, 1), # [512, 8, 8]\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),       # [512, 4, 4]\n","        )\n","        self.fc = nn.Sequential(\n","            nn.Dropout(0.4),\n","            nn.Linear(512*4*4, 1024),\n","            nn.ReLU(),\n","            nn.Linear(1024, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 11)\n","        )\n","\n","    def forward(self, x):\n","        out = self.cnn(x)\n","        out = out.view(out.size()[0], -1)\n","        return self.fc(out)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-05-06T13:22:24.269077Z","iopub.status.busy":"2023-05-06T13:22:24.268713Z","iopub.status.idle":"2023-05-06T13:22:24.306539Z","shell.execute_reply":"2023-05-06T13:22:24.305333Z","shell.execute_reply.started":"2023-05-06T13:22:24.269050Z"},"papermill":{"duration":0.054295,"end_time":"2022-02-23T10:03:08.266338","exception":false,"start_time":"2022-02-23T10:03:08.212043","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["One ./food11\\training sample ./food11\\training\\0_0.jpg\n","One ./food11\\validation sample ./food11\\validation\\0_0.jpg\n"]}],"source":["batch_size = 64\n","_dataset_dir = \"./food11\"\n","# Construct datasets.\n","# The argument \"loader\" tells how torchvision reads the data.\n","train_set = FoodDataset(os.path.join(_dataset_dir,\"training\"), tfm=train_tfm)\n","train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n","valid_set = FoodDataset(os.path.join(_dataset_dir,\"validation\"), tfm=test_tfm)\n","valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 128, 128]           1,792\n","       BatchNorm2d-2         [-1, 64, 128, 128]             128\n","              ReLU-3         [-1, 64, 128, 128]               0\n","         MaxPool2d-4           [-1, 64, 64, 64]               0\n","            Conv2d-5          [-1, 128, 64, 64]          73,856\n","       BatchNorm2d-6          [-1, 128, 64, 64]             256\n","              ReLU-7          [-1, 128, 64, 64]               0\n","         MaxPool2d-8          [-1, 128, 32, 32]               0\n","            Conv2d-9          [-1, 256, 32, 32]         295,168\n","      BatchNorm2d-10          [-1, 256, 32, 32]             512\n","             ReLU-11          [-1, 256, 32, 32]               0\n","        MaxPool2d-12          [-1, 256, 16, 16]               0\n","           Conv2d-13          [-1, 512, 16, 16]       1,180,160\n","      BatchNorm2d-14          [-1, 512, 16, 16]           1,024\n","             ReLU-15          [-1, 512, 16, 16]               0\n","        MaxPool2d-16            [-1, 512, 8, 8]               0\n","           Conv2d-17            [-1, 512, 8, 8]       2,359,808\n","      BatchNorm2d-18            [-1, 512, 8, 8]           1,024\n","             ReLU-19            [-1, 512, 8, 8]               0\n","        MaxPool2d-20            [-1, 512, 4, 4]               0\n","          Dropout-21                 [-1, 8192]               0\n","           Linear-22                 [-1, 1024]       8,389,632\n","             ReLU-23                 [-1, 1024]               0\n","           Linear-24                  [-1, 512]         524,800\n","             ReLU-25                  [-1, 512]               0\n","           Linear-26                   [-1, 11]           5,643\n","================================================================\n","Total params: 12,833,803\n","Trainable params: 12,833,803\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.19\n","Forward/backward pass size (MB): 49.65\n","Params size (MB): 48.96\n","Estimated Total Size (MB): 98.79\n","----------------------------------------------------------------\n"]}],"source":["# !pip install torchsummary\n","from torchsummary import summary\n","\n","model_show = Classifier().to('cuda')\n","summary(model_show, input_size=(3, 128, 128))\n"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["\n","import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n","\n","torch.cuda.init()\n","torch.backends.cudnn.benchmark = False\n"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-05-06T12:57:26.787400Z","iopub.status.busy":"2023-05-06T12:57:26.787049Z","iopub.status.idle":"2023-05-06T13:02:32.092906Z","shell.execute_reply":"2023-05-06T13:02:32.091821Z","shell.execute_reply.started":"2023-05-06T12:57:26.787370Z"},"papermill":{"duration":32830.720158,"end_time":"2022-02-23T19:10:19.001001","exception":false,"start_time":"2022-02-23T10:03:08.280843","status":"completed"},"tags":[],"trusted":true},"outputs":[{"ename":"RuntimeError","evalue":"CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[1;32mIn[27], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m patience \u001b[39m=\u001b[39m \u001b[39m8\u001b[39m \u001b[39m# If no improvement in 'patience' epochs, early stop\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[39m# Initialize a model, and put it on the device specified.\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m model \u001b[39m=\u001b[39m Classifier()\u001b[39m.\u001b[39;49mto(device)\n\u001b[0;32m     14\u001b[0m \u001b[39m# For the classification task, we use cross-entropy as the measurement of performance.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss()\n","File \u001b[1;32md:\\ProgrammingSoftwares\\Anaconda3\\envs\\pytorch39\\lib\\site-packages\\torch\\nn\\modules\\module.py:927\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    923\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    924\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m    925\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[1;32m--> 927\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n","File \u001b[1;32md:\\ProgrammingSoftwares\\Anaconda3\\envs\\pytorch39\\lib\\site-packages\\torch\\nn\\modules\\module.py:579\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    578\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 579\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    581\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    582\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    583\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    584\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    589\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    590\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n","File \u001b[1;32md:\\ProgrammingSoftwares\\Anaconda3\\envs\\pytorch39\\lib\\site-packages\\torch\\nn\\modules\\module.py:579\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    578\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 579\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    581\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    582\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    583\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    584\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    589\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    590\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n","File \u001b[1;32md:\\ProgrammingSoftwares\\Anaconda3\\envs\\pytorch39\\lib\\site-packages\\torch\\nn\\modules\\module.py:602\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    598\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    599\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    600\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    601\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 602\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[0;32m    603\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    604\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n","File \u001b[1;32md:\\ProgrammingSoftwares\\Anaconda3\\envs\\pytorch39\\lib\\site-packages\\torch\\nn\\modules\\module.py:925\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[0;32m    923\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    924\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m--> 925\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n","\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."]}],"source":["from torch.utils.tensorboard import SummaryWriter\n","writer = SummaryWriter()\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","n_epochs = 3\n","patience = 8 # If no improvement in 'patience' epochs, early stop\n","\n","model = Classifier().to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.0003, weight_decay=1e-5) \n","\n","stale = 0\n","best_acc = 0\n","\n","update_times = 0\n","for epoch in range(n_epochs):\n","\n","    # ---------- Training ----------\n","    # Make sure the model is in train mode before training.\n","    model.train()\n","\n","    # These are used to record information in training.\n","    train_loss = []\n","    train_accs = []\n","\n","    for batch in tqdm(train_loader):\n","        update_times += 1\n","     \n","        imgs, labels = batch\n","    \n","        logits = model(imgs.to(device))\n","\n","        # Calculate the cross-entropy loss.\n","        loss = criterion(logits, labels.to(device))\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","\n","        # Clip the gradient norms for stable training.\n","        grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n","        \n","        optimizer.step()\n","\n","        # Compute the accuracy for current batch.\n","        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n","\n","        # Record the loss and accuracy.\n","        train_loss.append(loss.item())\n","        train_accs.append(acc)\n","        \n","    train_loss = sum(train_loss) / len(train_loss)\n","    train_acc = sum(train_accs) / len(train_accs)\n","    writer.add_scalar('Accuracy/train', train_acc, update_times)\n","\n","    print(f\"[ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\")\n","\n","    # ---------- Validation ----------\n","    # Make sure the model is in eval mode so that some modules like dropout are disabled and work normally.\n","    model.eval()\n","\n","    valid_loss = []\n","    valid_accs = []\n","\n","    for batch in tqdm(valid_loader):\n","\n","        imgs, labels = batch\n","\n","        with torch.no_grad():\n","            logits = model(imgs.to(device))\n","\n","        loss = criterion(logits, labels.to(device))\n","\n","        # Compute the accuracy for current batch.\n","        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n","\n","        valid_loss.append(loss.item())\n","        valid_accs.append(acc)\n","    \n","    valid_loss = sum(valid_loss) / len(valid_loss)\n","    valid_acc = sum(valid_accs) / len(valid_accs)\n","    writer.add_scalar('Accuracy/valid', valid_acc, update_times)\n","    print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n","\n","\n","    # update logs\n","    if valid_acc > best_acc:\n","        with open(f\"./{_exp_name}_log.txt\",\"a\"):\n","            print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f} -> best\")\n","    else:\n","        with open(f\"./{_exp_name}_log.txt\",\"a\"):\n","            print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n","\n","\n","    # save models\n","    if valid_acc > best_acc:\n","        print(f\"Best model found at epoch {epoch}, saving model\")\n","        torch.save(model.state_dict(), f\"{_exp_name}_best.ckpt\") # only save best to prevent output memory exceed error\n","        best_acc = valid_acc\n","        stale = 0\n","    else:\n","        stale += 1\n","        if stale > patience:\n","            print(f\"No improvment {patience} consecutive epochs, early stopping\")\n","            break"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-06T13:03:48.071486Z","iopub.status.busy":"2023-05-06T13:03:48.071133Z","iopub.status.idle":"2023-05-06T13:03:48.085800Z","shell.execute_reply":"2023-05-06T13:03:48.084867Z","shell.execute_reply.started":"2023-05-06T13:03:48.071456Z"},"trusted":true},"outputs":[],"source":["%reload_ext tensorboard\n","%tensorboard --logdir=./runs/"]},{"attachments":{},"cell_type":"markdown","metadata":{"papermill":{"duration":0.498773,"end_time":"2022-02-23T19:10:20.961802","exception":false,"start_time":"2022-02-23T19:10:20.463029","status":"completed"},"tags":[]},"source":["## Testing and generate prediction CSV"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-05-06T12:53:52.994874Z","iopub.status.idle":"2023-05-06T12:53:52.995749Z","shell.execute_reply":"2023-05-06T12:53:52.995500Z","shell.execute_reply.started":"2023-05-06T12:53:52.995470Z"},"papermill":{"duration":0.493644,"end_time":"2022-02-23T19:10:19.985992","exception":false,"start_time":"2022-02-23T19:10:19.492348","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["test_set = FoodDataset(os.path.join(_dataset_dir,\"test\"), tfm=test_tfm)\n","test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-05-06T12:53:52.997206Z","iopub.status.idle":"2023-05-06T12:53:52.997660Z","shell.execute_reply":"2023-05-06T12:53:52.997440Z","shell.execute_reply.started":"2023-05-06T12:53:52.997419Z"},"papermill":{"duration":49.157727,"end_time":"2022-02-23T19:11:10.61523","exception":false,"start_time":"2022-02-23T19:10:21.457503","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["model_best = Classifier().to(device)\n","model_best.load_state_dict(torch.load(f\"{_exp_name}_best.ckpt\"))\n","model_best.eval()\n","prediction = []\n","with torch.no_grad():\n","    for data,_ in test_loader:\n","        test_pred = model_best(data.to(device))\n","        test_label = np.argmax(test_pred.cpu().data.numpy(), axis=1)\n","        prediction += test_label.squeeze().tolist()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-05-06T12:53:53.001058Z","iopub.status.idle":"2023-05-06T12:53:53.001502Z","shell.execute_reply":"2023-05-06T12:53:53.001301Z","shell.execute_reply.started":"2023-05-06T12:53:53.001280Z"},"papermill":{"duration":0.554276,"end_time":"2022-02-23T19:11:11.870035","exception":false,"start_time":"2022-02-23T19:11:11.315759","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["#create test csv\n","def pad4(i):\n","    return \"0\"*(4-len(str(i)))+str(i)\n","df = pd.DataFrame()\n","df[\"Id\"] = [pad4(i) for i in range(1,len(test_set)+1)]\n","df[\"Category\"] = prediction\n","df.to_csv(\"submission.csv\",index = False)"]}],"metadata":{"kernelspec":{"display_name":"pytorch","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":4}
